{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8UUkDGJO0JW1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_report(y_test, predictions):\n",
    "    print('MSE', mean_squared_error(y_test,predictions))\n",
    "    print('MAE', mean_absolute_error(y_test,predictions))\n",
    "    print('R2', r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QjM3NKE1x-a",
    "outputId": "ba389286-45a8-449c-b205-ce9432555f37"
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "num_test = 10  # the last 10 samples as testing set\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = boston.data[:-num_test, :]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = boston.target[:-num_test].reshape(-1, 1)\n",
    "X_test = boston.data[-num_test:, :]\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = boston.target[-num_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSymTMaY349i",
    "outputId": "36f36139-fa77-4356-a1bc-6505347e8803"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pradeep/miniconda3/envs/cv_env/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 13.933482332708788\n",
      "MAE 2.5619954224732617\n",
      "R2 -0.2829976089270627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pradeep/miniconda3/envs/cv_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_scikit = MLPRegressor(hidden_layer_sizes=(16, 8), activation='relu', solver='adam',\n",
    "                         learning_rate_init=0.001, random_state=42, max_iter=2000)\n",
    "nn_scikit.fit(X_train, y_train)\n",
    "predictions = nn_scikit.predict(X_test)\n",
    "regression_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzIxUkxc4sS1",
    "outputId": "13da7947-9290-44c4-83b5-d623cf265a5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 6ms/step - loss: 652.6162\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 606.7444\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 581.7372\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 582.6802\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 555.5733\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 518.4768\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 518.9052\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 531.3969\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 482.5914\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 458.5640\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 444.0836\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 417.6828\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 366.5056\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 338.8930\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 316.9968\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 284.0485\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 255.6285\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 218.8436\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 183.4446\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 141.6751\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 121.7316\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 87.6428\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 74.7167\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.2389\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.8122\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.2508\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.5959\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.1204\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.4813\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9702\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4168\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 26.8405\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2627\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 21.2994\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23.1671\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22.7276\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24.7834\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 22.9319\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21.3273\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19.4643\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 21.1304\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 22.3060\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 20.6312\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 20.0116\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18.7788\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 19.4182\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 24.1144\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21.2614\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 21.1951\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 16.2514\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16.7065\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20.2797\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18.6039\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 19.6435\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 18.2236\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19.5637\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 20.6280\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16.9087\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 18.1696\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 18.3005\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 15.6925\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 15.5785\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.7817\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19.7166\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 17.3948\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16.7841\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16.1229\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.1863\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 15.9696\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 15.9288\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13.3184\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16.7408\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18.6056\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 15.1281\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.7301\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14.5039\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.3064\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.6105\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14.3923\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 15.2345\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.6619\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.0902\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.3356\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.6702\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.9101\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.2424\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.3319\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.4018\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.7007\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.9877\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.3682\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.3652\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.0288\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 14.1709\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 15.0937\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.2812\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.6906\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.6601\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.9446\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.8986\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.8198\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12.6315\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.1289\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 14.1222\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.4778\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.5181\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.0334\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.9079\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.4362\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11.4515\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.2730\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.0655\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.4545\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.0494\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.0155\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.0931\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 10.6372\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11.0789\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.8590\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.4347\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 13.6280\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.4501\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11.1951\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.1781\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.6094\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.6604\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.0461\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.3596\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 10.02 - 0s 4ms/step - loss: 10.3421\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12.1195\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.9701\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.2341\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11.3098\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.9574\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.9273\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11.7943\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 10.1182\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.1850\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.3072\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.4343\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.3743\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.7930\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.7513\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.2096\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12.3283\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.0281\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.5083\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.4142\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.6141\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.5069\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.2751\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 10.7324\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.6206\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.0388\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.2838\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.6178\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.7238\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.3925\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.7454\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.5967\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3685\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.7285\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.3322\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.3606\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.4292\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.6246\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.1503\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.7759\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.9551\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.6311\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.9444\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.7661\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.1967\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.5237\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.2105\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.3828\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6868\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.1893\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8.5409\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.7356\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.3187\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.2010\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11.2147\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.7363\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.4411\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.9875\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 10.4924\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.3286\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.7434\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.0202\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 10.0761\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.6549\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.7713\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.7568\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.6199\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.5693\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 10.1377\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.1235\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.9319\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.5433\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.5940\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.2780\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.3406\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.7529\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.8135\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.9193\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.8634\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.6723\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 9.9565\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8.7544\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 9.8013\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.9413\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.6549\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9866\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0844\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.9176\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.2554\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.9991\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.4412\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.1398\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.3097\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.3225\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8.4296\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.2088\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.6797\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1826\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.9719\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.2824\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.3675\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 7.5053\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.7555\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.4649\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 7.7649\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8.2853\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6.4470\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 7.8123\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3567\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.5760\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.6596\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.0631\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.9703\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1275\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.8976\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.7755\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9512\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.1797\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8537\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.9381\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.8726\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3903\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8.2832\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 8.3413\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.3569\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.2893\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.8637\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7.6234\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.2388\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.0296\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.1400\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.7768\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.8595\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.8795\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.4691\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4876\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9124\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.2166\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.4608\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.4259\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.4995\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6688\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.0516\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.4600\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5893\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.6242\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.8449\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4785\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.4739\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.0065\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.3134\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.5076\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.3779\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8839\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.7615\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.9351\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.1010\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.2773\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.6707\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.9215\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5683\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.3027\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7548\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.2835\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.2954\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1992\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.9775\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.1737\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.6913\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0438\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.1429\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.7989\n",
      "MSE 16.980902433981754\n",
      "MAE 3.1843055343627933\n",
      "R2 -0.563604610821425\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units=16, activation='relu'),\n",
    "    keras.layers.Dense(units=8, activation='relu'),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam())\n",
    "model.fit(X_train, y_train, epochs=300)\n",
    "predictions = model.predict(X_test)[:, 0]\n",
    "regression_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtwD5fPM7HSZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
